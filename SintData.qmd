---
title: "Gera√ß√£o de dados sint√©ticos x datasets de s√©ries de pre√ßos conhecidos"
format:
  html:
    self-contained: true
    toc: true
    code-fold: true
    df-print: paged
editor: visual
---

------------------------------------------------------------------------

<left> ![](https://raw.githubusercontent.com/profrhozon/site/main/logo_FAE.png){width="15%"} </left>

------------------------------------------------------------------------

```{r setup, include=FALSE}

knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	comment = NA
)
knitr::opts_chunk$set(comment = NA)    # Remove all coments # of R outputs
knitr::opts_chunk$set(warning = FALSE) # Remove all warnings # of R outputs
knitr::opts_chunk$set(message = FALSE) # Remove all messages # of R outputs

```

::: callout-note
## Resumo

Nesta aula veremos um pouco de alguns assuntos fundamentais e √∫teis que nos auxiliar√£o a "destravar" em nosso processo de utiliza√ß√£o de dados para nossos prop√≥sitos de atua√ß√£o como Cientistas de Dados. Os t√≥picos que abordaremos hoje permear√£o:

-   O uso de conjuntos de dados de s√©ries temporais financeiras conhecidos na comunidade;
-   O uso de API¬¥s para download de dados de s√©ries de pre√ßos livremente
-   Algumas t√©cnicas extremamente √∫teis de gera√ß√£o de dados sint√©ticos
:::

<center>![](https://cdn.prod.website-files.com/65264f6bf54e751c3a776db1/6530058c5159f040612deed1_continuous-training.gif){width="50%"}</center>

<small>

**Fonte:** [zeml.io](https://www.zenml.io/blog/how-to-painlessly-deploy-your-ml-models-with-zenml)

</small>

## **üìå Introdu√ß√£o: Conjuntos de Dados P√∫blicos e Sele√ß√£o de Portf√≥lio**

```{=html}
<!-- 
Escrever a intro do documento aqui ....
-->
```

Nesta aula, abordaremos um dos pilares fundamentais da modelagem quantitativa em finan√ßas: a utiliza√ß√£o de **dados financeiros** para a constru√ß√£o e an√°lise de portf√≥lios.

Para tal, exploraremos tr√™s grandes abordagens no uso de **s√©ries temporais financeiras**:

1.  **Uso de datasets conhecidos**
    -   Algumas bases de dados amplamente utilizadas na literatura e dispon√≠veis dentro de pacotes do **R** e outras fontes confi√°veis como o **Kaggle** e **ScienceDirect**.
    -   Exemplos incluem o **dataset `oil` (pre√ßos de contratos futuros de petr√≥leo), `EuStockMarkets` (√≠ndices europeus), `edhec` (retornos de hedge funds), e `LPP2005REC` (retornos de ativos financeiros europeus)**.
2.  **Obten√ß√£o de dados reais via APIs**
    -   Demonstramos como utilizar APIs p√∫blicas, como a do **Yahoo Finance**, para baixar dados hist√≥ricos de a√ß√µes e commodities, diretamente para o R ou Python.
    -   O objetivo √© capacitar os alunos a construir **portf√≥lios reais**, utilizando fontes p√∫blicas de dados financeiros.
3.  **Gera√ß√£o de dados sint√©ticos**
    -   Introduzimos m√©todos para gerar **dados sint√©ticos**, como o **Movimento Browniano Geom√©trico (MGB)**, **distribui√ß√µes lognormais**, **caminhos aleat√≥rios com ru√≠do gaussiano** e **redes adversariais generativas (GANs)**.
    -   O prop√≥sito desses m√©todos √© fornecer alternativas para an√°lise de portf√≥lios quando n√£o h√° dados reais dispon√≠veis ou quando h√° restri√ß√µes de privacidade e confidencialidade.

üí° **Por que isso √© importante?**\
- Muitas vezes, dados reais s√£o **incompletos, inconsistentes ou indispon√≠veis**, tornando essencial o conhecimento de t√©cnicas de **simula√ß√£o e modelagem de s√©ries temporais**. - O aprendizado dessas abordagens permite aos alunos **tomar decis√µes informadas** sobre quais m√©todos utilizar na modelagem de portf√≥lios financeiros, seja para an√°lise de risco, previs√£o de pre√ßos ou otimiza√ß√£o de carteiras.

üöÄ **Objetivo da aula**\
- Compreender as **vantagens e limita√ß√µes** de cada uma dessas abordagens.\
- Desenvolver habilidades pr√°ticas na **obten√ß√£o e manipula√ß√£o de dados financeiros**.\
- Implementar t√©cnicas para **an√°lise e simula√ß√£o de portf√≥lios**, combinando ferramentas do R e Python.

::: panel-tabset
## Datasets p√∫blicos

Vamos come√ßar com alguns datasets que vem dentro de alguns pacotes do R:

-   <mark>O dataset `oil`dispon√≠vel no pacote GAMLSS do R $\Downarrow$</mark>

```{r}

library(gamlss) # Uso do dataset ¬¥oil¬¥ disponibilizado dentro do pacote gamlss do R

data(oil)

dplyr::glimpse(oil)

```

**Cada vari√°vel nas colunas denota o seguinte sentido** (Stasinopoulos *et al.* 2017, p. 413):

-   **`OILPRICE`**\
    ‚áí o logaritmo do pre√ßo do contrato de petr√≥leo WTI de vencimento mais pr√≥ximo negociado na NYMEX ‚Äì em termos financeiros, este √© o CL1. Essa √© a vari√°vel resposta.

-   **`CL2_log, CL3_log, CL4_log, CL5_log, CL6_log, CL7_log, CL8_log, CL9_log, CL10_log, CL11_log, CL12_log, CL13_log, CL14_log, CL15_log`**\
    ‚áí s√£o os logaritmos dos pre√ßos dos contratos de petr√≥leo WTI para vencimentos de 2 a 15 meses √† frente negociados na NYMEX. Por exemplo, para o dia de negocia√ß√£o de 2 de junho de 2016, o CL2 corresponde ao contrato de petr√≥leo WTI para entrega em agosto de 2016.

-   **`BDIY_log`**\
    ‚áí o Baltic Dry Index, que √© uma avalia√ß√£o do pre√ßo para transportar as principais mat√©rias-primas por via mar√≠tima.

-   **`SPX_log`**\
    ‚áí o √≠ndice S&P 500.

-   **`DX1_log`**\
    ‚áí o √≠ndice do d√≥lar americano.

-   **`GC1_log`**\
    ‚áí o logaritmo do pre√ßo do contrato de ouro com vencimento mais pr√≥ximo negociado na NYMEX.

-   **`HO1_log`**\
    ‚áí o logaritmo do pre√ßo do contrato de √≥leo de aquecimento (heating oil) de vencimento mais pr√≥ximo negociado na NYMEX.

-   **`USCI_log`**\
    ‚áí o √≠ndice de commodities dos Estados Unidos.

-   **`GNR_log`**\
    ‚áí o √≠ndice S&P Global Natural Resources.

-   **`SHCOMP_log`**\
    ‚áí o √≠ndice composto da Bolsa de Valores de Xangai.

-   **`FTSE_log`**\
    ‚áí o √≠ndice FTSE 100.

-   **`respLAG`**\
    ‚áí o defasagem 1 de `OILPRICE` ‚Äì ou seja, a vers√£o defasada da vari√°vel resposta.

------------------------------------------------------------------------

Vamos vendo outros conjuntos de dados:

**Para os demais datasets, consulte a documenta√ß√£o do pacote para maiores detalhamentos**.

-   <mark>Dataset `EuStockMarkets` do pacote `tseries` $\Downarrow$</mark>

```{r}

library(tseries)

data(EuStockMarkets)            # Carrega o dataset EuStockMarkets 
dplyr::glimpse(EuStockMarkets)  # Visualiza uma pr√©via dos dados

```

*EuStockMarkets* √© um dataset cl√°ssico do R (dispon√≠vel via `data("EuStockMarkets")`) que agrega dados di√°rios dos principais √≠ndices de a√ß√µes europeus.

**Significado das colunas do dataset `EuStockMarkets` (pacote tseries):**

-   **DAX**\
    ‚áí √çndice de a√ß√µes da bolsa alem√£, que reflete o desempenho das maiores empresas negociadas na Alemanha.

-   **SMI**\
    ‚áí √çndice do mercado su√≠√ßo, representando o comportamento das principais a√ß√µes da Su√≠√ßa.

-   **CAC**\
    ‚áí √çndice franc√™s (CAC 40), que mede o desempenho das 40 maiores empresas da bolsa de Paris.

-   **FTSE**\
    ‚áí √çndice do mercado do Reino Unido (FTSE 100), representando as 100 maiores empresas listadas na bolsa de Londres.

*Observa√ß√£o:* O dataset `EuStockMarkets` cont√©m cota√ß√µes di√°rias (pre√ßos de fechamento) desses quatro √≠ndices durante um per√≠odo espec√≠fico.

------------------------------------------------------------------------

-   <mark>Dataset `edhec` do pacote `PerformanceAnalytics` $\Downarrow$</mark>

```{r}

library(PerformanceAnalytics)

data(edhec)                # Carrega o dataset 'edhec'
dplyr::glimpse(edhec)      # Visualiza uma pr√©via dos dados

```

**Significado das colunas do dataset `edhec` (do pacote PerformanceAnalytics):**

-   **Convertible Arbitrage**\
    Retornos mensais de fundos que operam com estrat√©gias de arbitragem convers√≠vel, buscando lucrar com as discrep√¢ncias entre os pre√ßos das a√ß√µes e dos t√≠tulos convers√≠veis.

-   **CTA Global**\
    Retornos mensais de fundos que seguem estrat√©gias de Commodity Trading Advisor (CTA) globais, operando em diversos mercados ‚Äì como commodities, moedas e √≠ndices ‚Äì com a ideia de capturar tend√™ncias sistem√°ticas.

-   **Emerging Markets**\
    Retornos mensais de fundos que investem em mercados emergentes, aproveitando oportunidades (e riscos) associados a economias em desenvolvimento.

-   **Event Driven**\
    Retornos mensais de fundos que buscam explorar oportunidades decorrentes de eventos corporativos (como fus√µes, aquisi√ß√µes, reestrutura√ß√µes, etc.) que possam gerar disloca√ß√µes tempor√°rias nos pre√ßos dos ativos.

-   **Long/Short Equity**\
    Retornos mensais de fundos que adotam estrat√©gias de compra (long) e venda (short) de a√ß√µes, visando capturar ganhos tanto com movimentos de alta quanto de baixa dos pre√ßos das a√ß√µes.

-   **Macro**\
    Retornos mensais de fundos macro, que investem com base em grandes tend√™ncias e eventos macroecon√¥micos, utilizando informa√ß√µes econ√¥micas globais para orientar suas posi√ß√µes.

-   **Relative Value**\
    Retornos mensais de fundos que exploram discrep√¢ncias de pre√ßos entre ativos relacionados, utilizando estrat√©gias de arbitragem para capturar ganhos quando os pre√ßos se reequilibram.

-   **Equity Market Neutral**\
    Retornos mensais de fundos que buscam neutralizar a exposi√ß√£o ao mercado geral de a√ß√µes, focando na captura de ganhos relativos entre pares de a√ß√µes, independentemente da dire√ß√£o do mercado.

-   **Fixed Income Arbitrage**\
    Retornos mensais de fundos que utilizam estrat√©gias de arbitragem no mercado de renda fixa, explorando inefici√™ncias entre os pre√ßos dos t√≠tulos e suas taxas de juros.

-   **Multi-Strategy**\
    Retornos mensais de fundos que combinam diversas estrat√©gias (por exemplo, long/short, arbitragem, macro, etc.) em uma √∫nica carteira, visando diversifica√ß√£o dos riscos e das fontes de retorno.

-   **All Hedge Funds**\
    Um √≠ndice composto que agrega os retornos de m√∫ltiplas estrat√©gias de hedge funds, servindo como uma refer√™ncia global do desempenho dos fundos de hedge.

**Lembrando que preferencialmente o conjunto de dados escolhido pelo seu grupo dever√° ser como uma carteira de ativos financeiros, geralmente regidos por s√©ries de pre√ßos e consequentemente seus retornos e volatilidades.**

------------------------------------------------------------------------

-   <mark>`LPP2005REC` (Pacote `fPortfolio`) $\Downarrow$ </mark>

O dataset `LPP2005REC` cont√©m os retornos mensais de carteiras de ativos financeiros europeus, sendo ideal para an√°lises de desempenho, retorno e risco.

```{r}

library(fPortfolio)
data(LPP2005REC)           # Carrega o dataset 'LPP2005REC'
dplyr::glimpse(LPP2005REC) # Visualiza uma pr√©via dos dados

```

**Significado das colunas no dataset `edhec` (pacote PerformanceAnalytics):**

-   **Convertible Arbitrage**\
    ‚áí Retornos mensais de fundos que exploram discrep√¢ncias de pre√ßos entre t√≠tulos convers√≠veis e suas a√ß√µes subjacentes, buscando lucrar com a arbitragem entre esses instrumentos.

-   **CTA Global**\
    ‚áí Retornos mensais de consultores de negocia√ß√£o de commodities (Commodity Trading Advisors) que operam globalmente, utilizando estrat√©gias sistem√°ticas ou discricion√°rias em mercados de futuros e de c√¢mbio.

-   **Distressed Securities**\
    ‚áí Retornos mensais de fundos que investem em t√≠tulos de empresas em dificuldades financeiras ou em situa√ß√£o de fal√™ncia, visando lucrar com a recupera√ß√£o ou reestrutura√ß√£o dessas empresas.

-   **Emerging Markets**\
    ‚áí Retornos mensais de fundos que investem em mercados emergentes, buscando oportunidades de crescimento em economias em desenvolvimento.

-   **Equity Market Neutral**\
    ‚áí Retornos mensais de fundos que buscam neutralizar a exposi√ß√£o ao mercado acion√°rio, equilibrando posi√ß√µes compradas e vendidas para isolar ganhos relativos entre a√ß√µes.

-   **Event Driven**\
    ‚áí Retornos mensais de fundos que exploram oportunidades decorrentes de eventos corporativos espec√≠ficos, como fus√µes, aquisi√ß√µes ou reestrutura√ß√µes.

-   **Fixed Income Arbitrage**\
    ‚áí Retornos mensais de fundos que buscam lucrar com inefici√™ncias nos mercados de renda fixa, explorando discrep√¢ncias de pre√ßos entre t√≠tulos e suas taxas de juros.

-   **Global Macro**\
    ‚áí Retornos mensais de fundos que utilizam estrat√©gias baseadas em tend√™ncias macroecon√¥micas globais, investindo em uma variedade de ativos para capitalizar mudan√ßas econ√¥micas amplas.

-   **Long/Short Equity**\
    ‚áí Retornos mensais de fundos que adotam posi√ß√µes compradas e vendidas em a√ß√µes, visando lucrar tanto com a valoriza√ß√£o quanto com a desvaloriza√ß√£o de ativos espec√≠ficos.

-   **Merger Arbitrage**\
    ‚áí Retornos mensais de fundos que exploram oportunidades de arbitragem em opera√ß√µes de fus√£o e aquisi√ß√£o, buscando lucrar com as diferen√ßas de pre√ßo entre a oferta e o valor de mercado das empresas envolvidas.

-   **Relative Value**\
    ‚áí Retornos mensais de fundos que buscam explorar discrep√¢ncias de pre√ßos entre ativos relacionados, utilizando estrat√©gias de arbitragem para capturar ganhos quando os pre√ßos se ajustam.

-   **Short Selling**\
    ‚áí Retornos mensais de fundos que se especializam em vender ativos a descoberto, apostando na queda de pre√ßos para obter lucro.

-   **Funds of Funds**\
    ‚áí Retornos mensais de fundos que investem em uma carteira diversificada de outros fundos hedge, buscando reduzir o risco atrav√©s da diversifica√ß√£o entre diferentes estrat√©gias e gestores.

*Observa√ß√£o:* O dataset `edhec` cont√©m os retornos mensais dessas 13 estrat√©gias de fundos hedge, fornecendo uma vis√£o abrangente do desempenho de diferentes abordagens de investimento ao longo do tempo.

------------------------------------------------------------------------

O [Kaggle](https://www.kaggle.com/) oferece diversos datasets relacionados ao mercado financeiro. Por exemplo:

-   **Time Series Financial Portfolio Data**\
    Este dataset cont√©m dados hist√≥ricos de pre√ßos de a√ß√µes, permitindo an√°lises de s√©ries temporais no contexto financeiro. Dispon√≠vel em: <https://www.kaggle.com/datasets/karunyaronith/time-series-financial-portfolio-data>

$\Rightarrow$ üìÇ Dataset Adicional: FAANG Complete Stock Data (Kaggle)

Al√©m dos conjuntos de dados mencionados anteriormente, um dataset relevante para an√°lises financeiras √© o **FAANG Complete Stock Data**, dispon√≠vel no Kaggle:

üîó [**FAANG Complete Stock Data**](https://www.kaggle.com/datasets/aayushmishra1512/faang-complete-stock-data)

üìå **Descri√ß√£o**:

Este conjunto de dados cont√©m informa√ß√µes completas sobre os pre√ßos das a√ß√µes das cinco maiores empresas de tecnologia conhecidas como **FAANG**:

-   **Facebook (agora Meta - META)**
-   **Apple (AAPL)**
-   **Amazon (AMZN)**
-   **Netflix (NFLX)**
-   **Google (agora Alphabet - GOOGL)**

üóÇ **Colunas dispon√≠veis**:

-   `Date`: Data da negocia√ß√£o.
-   `Open`: Pre√ßo de abertura da a√ß√£o.
-   `High`: Pre√ßo m√°ximo do dia.
-   `Low`: Pre√ßo m√≠nimo do dia.
-   `Close`: Pre√ßo de fechamento ajustado.
-   `Volume`: Volume negociado no dia.
-   `Company`: Empresa correspondente ao dado.

üìä **Poss√≠veis Aplica√ß√µes**:

-   An√°lise comparativa do desempenho das empresas FAANG ao longo do tempo.
-   Modelagem de s√©ries temporais financeiras para previs√£o de pre√ßos.
-   Simula√ß√µes de carteiras de investimentos baseadas em grandes empresas do setor de tecnologia.

üí° **Dica**: Para carregar os dados diretamente no R ou Python, o arquivo pode ser baixado em formato CSV e importado para an√°lise, facilitando a aplica√ß√£o de modelos de previs√£o e an√°lise de risco.

------------------------------------------------------------------------

O [ScienceDirect](https://www.sciencedirect.com/) disponibiliza um artigo que acompanha um conjunto de dados real abrangente para avalia√ß√£o de estrat√©gias de portf√≥lio. O dataset pode ser √∫til para an√°lises de s√©ries temporais financeiras. Dispon√≠vel em: <https://www.sciencedirect.com/science/article/pii/S2352340916303997>

**Nota:** Ao utilizar dados de fontes p√∫blicas, √© importante verificar a qualidade e a atualiza√ß√£o das informa√ß√µes, garantindo que elas sejam adequadas para os objetivos espec√≠ficos de an√°lise.

## O uso de API¬¥s

<center>![](https://raw.githubusercontent.com/profrhozon/site/main/meme_datasets.jpg){width="50%"}</center>

Existe uma outra forma de fazer nosso conjunto de dados, que consiste em montarmos nossa carteira, utilizando algumas fontes free p√∫blicas:

Abaixo est√£o algumas fontes confi√°veis onde voc√™ pode baixar dados hist√≥ricos de pre√ßos de a√ß√µes e commodities, ideais para a constru√ß√£o e an√°lise de portf√≥lios financeiros.

------------------------------------------------------------------------

### 1. Yahoo Finance

-   **Descri√ß√£o:**\
    O Yahoo Finance oferece dados hist√≥ricos de pre√ßos de a√ß√µes e commodities, que podem ser baixados diretamente via API (c√≥digo mais a frente) ou via download direto do csv.

-   **Como baixar:**

    1.  Acesse o [Yahoo Finan√ßas](https://finance.yahoo.com/).
    2.  Insira o ticker do ativo desejado na barra de pesquisa (por exemplo, "AAPL" para Apple).
    3.  Na p√°gina do ativo, clique na aba "Historical Data" (Dados Hist√≥ricos).
    4.  Selecione o per√≠odo e a frequ√™ncia dos dados.
    5.  Clique em "Download" para obter o arquivo CSV.

-   **Refer√™ncia:**\
    [Como baixar dados hist√≥ricos no Yahoo Finan√ßas](https://br.ajuda.yahoo.com/kb/SLN2311.html)

<mark> **Me parece que essa op√ß√£o de donwload do csv foi desabiitada** </mark>

------------------------------------------------------------------------

### 2. ADVFN Brasil

-   **Descri√ß√£o:**\
    A ADVFN Brasil disponibiliza dados hist√≥ricos de a√ß√µes, √≠ndices e commodities negociados na B3 (Bolsa de Valores do Brasil) e em outras bolsas internacionais, que podem ser baixados em formato CSV.

-   **Como baixar:**

    1.  Acesse a se√ß√£o de [Downloads de Dados Hist√≥ricos](https://br.advfn.com/ferramentas-de-investimento/data-downloads) no site da ADVFN.
    2.  Escolha o ativo desejado e o per√≠odo de interesse.
    3.  Baixe o arquivo CSV correspondente.

-   **Refer√™ncia:**\
    [Downloads de dados hist√≥ricos - ADVFN](https://br.advfn.com/ferramentas-de-investimento/data-downloads)

<mark> Me parece que exige que voc√™ crie uma conta antes </mark>

------------------------------------------------------------------------

### 3. Investing.com

-   **Descri√ß√£o:**\
    O Investing.com oferece dados hist√≥ricos de diversos ativos, incluindo a√ß√µes e commodities, que podem ser baixados em formato CSV.

-   **Como baixar:**

    1.  Acesse o [Investing.com](https://br.investing.com/).
    2.  Utilize a barra de pesquisa para encontrar o ativo desejado.
    3.  Na p√°gina do ativo, v√° para a se√ß√£o de dados hist√≥ricos.
    4.  Selecione o per√≠odo e clique em "Baixar dados" para obter o arquivo CSV.

-   **Exemplo:**\
    [Hist√≥rico de Pre√ßos - Futuros Mini Ibovespa](https://br.investing.com/indices/bovespa-win-futures-historical-data)

------------------------------------------------------------------------

**Nota:** Ao utilizar esses dados, √© importante verificar a qualidade e a atualiza√ß√£o das informa√ß√µes, garantindo que elas sejam adequadas para os objetivos espec√≠ficos de an√°lise.

### Montando sua carteira usando libs do Python e pacotes do R via Yahoo!Finance

Aqui poderemos selecionar os tickers (c√≥digos de empresas) que desejarmos pesquisando os nomes delas diretamente na barra de busca do Yahoo!Finance e simplesmente inserindo elas no c√≥digo Python ou R:

### Python

```{python}

# Importa as libs

from yahooquery import Ticker
import pandas as pd
from plotnine import ggplot, aes, geom_line, facet_wrap, labs, theme, element_text, theme_minimal

```

A carteira de tech companies que escolhi cont√©m os seguintes pre√ßos:

-   Apple
-   Microsoft
-   Amazon
-   Google
-   Meta

Definindo os tickers da carteira:

```{python}

# Definindo os tickers das a√ß√µes
TICKERS = [
    "AAPL",  # Apple Inc.
    "MSFT",  # Microsoft Corporation
    "AMZN",  # Amazon.com Inc.
    "GOOGL", # Alphabet Inc. (Google)
    "META"   # Meta Platforms Inc. (Facebook)
]

```

Baixando os dados do Yahoo Finance

```{python}

# Baixar os dados hist√≥ricos com yahooquery
tickers = Ticker(TICKERS)
data = tickers.history(period="5y")

# Resetar o √≠ndice corretamente
data = data.reset_index()

# Exibir as primeiras linhas para verificar a estrutura
print(data.head())

# O yahooquery retorna um MultiIndex, ent√£o √© preciso garantir que a coluna "date" exista corretamente
if "date" not in data.columns:
    raise ValueError("A coluna 'date' n√£o foi encontrada no dataset! Verifique a estrutura do DataFrame.")

# Selecionar apenas as colunas de interesse e reformatar
portfolio_prices = data.pivot(index="date", columns="symbol", values="close").reset_index()

# Garantir que n√£o h√° valores ausentes
portfolio_prices.dropna(inplace=True)

```

Vamos gerar um preview do nosso dataset (carteira ou portfolio) criado:

```{r}

library(DT)
library(reticulate)

# Importar a vari√°vel do Python para o R
portfolio_prices <- py$portfolio_prices

# Visualizar com DT
datatable(portfolio_prices, options = list(pageLength = 10, scrollX = TRUE))

```

Visualizando as s√©ries temporais dos pre√ßos lado a lado

```{r fig.width=9, fig.height=9}

library(dplyr)
library(tidyverse)
library(timetk)

# Importar os dados do Python para o R
portfolio_prices <- py$portfolio_prices

# Converter a coluna "date" para formato Date no R
portfolio_prices <- portfolio_prices |> 
  mutate(date = as.Date(unlist(date), format = "%Y-%m-%d"))

#glimpse(portfolio_prices) # Preview do dataset com o R (muito melhor que o Python ...heheheh)

portfolio_prices |> 
  pivot_longer(
    cols = -date,  # Todas as colunas, exceto "date"
    names_to = "Empresa",
    values_to = "Valor"
  ) |> 
  group_by(Empresa) |> 
  plot_time_series(
    .date_var = date,
    .value = Valor,
    .interactive = FALSE,  # Mude para TRUE para visualiza√ß√£o interativa
    .facet_ncol = 2,
    .smooth = FALSE
  ) +
  theme(
    strip.background = element_rect(fill = "white", colour = "white")
  )

```

### Carteira de commodities no R

Monto uma carteira s√≥ com commodities (gr√£os) usando o R:

```{r}

library(tidyverse)
library(dplyr)
library(ggplot2)
#library(plotly)
library(timeSeries)
library(fPortfolio)
library(quantmod)
library(cowplot) # devtools::install_github("wilkelab/cowplot/")
library(lattice)
library(timetk)

```

```{r}

tickers <- c(
         "ZC=F", # Corn Futures
         "ZO=F", # Wheat Futures
         "KE=F", # Futuros KC HRW Wheat Futures
         "ZR=F", # Rough Rice Futures
         "GF=F", # Feeder Cattle Futures
         "ZS=F", # SoyMeal Futures 
         "ZM=F", # Futuros farelo soja
         "ZL=F"  # SoyBeans Futures
)

```

Ent√£o baixo os dados via Yahoo!Finance:

```{r}

portfolioPrices <- NULL
  for ( Ticker in tickers )
    portfolioPrices <- cbind(
      portfolioPrices, 
      getSymbols.yahoo(
        Ticker,
        from = "2019-01-01",
        auto.assign = FALSE
      )[,4]
    )

portfolioPrices <- portfolioPrices[apply(portfolioPrices, 1, function(x) all(!is.na(x))),]

colnames(portfolioPrices) <- c(
  "corn_fut",
  "wheat_fut",
  "KCWheat_fut",
  "rice_fut",
  "Feeder_Cattle",
  "soymeal_fut",
  "soyF_fut",
  "soybeans_fut"
)

# Visualizar com DT
datatable(tail(portfolioPrices), options = list(pageLength = 10, scrollX = TRUE)) 

```

Visualizando os dados, temos:

```{r fig.width=9, fig.height=9}

portfolioPrices |> as.data.frame() |>
  mutate(
    time = seq_along( corn_fut )
  ) |>
  pivot_longer(
    !time,
    names_to = "Variables",
    values_to = "Value"  
      ) |>
  group_by(Variables) |>
  plot_time_series(
    time,
    Value,
    .interactive = F, # Change for TRUE for better visualization
    .facet_ncol = 2,
    .smooth = FALSE
  ) +
  theme(
    strip.background = element_rect(fill = "white", colour = "white")
  )

```
:::

# Gera√ß√£o de dados sint√©ticos

Gera√ß√£o de dados sint√©ticos refere-se ao processo de criar artificialmente dados que simulam caracter√≠sticas estat√≠sticas ou simula√ß√µes que refletem os padr√µes de um conjunto de dados real.

<center>![](https://raw.githubusercontent.com/profrhozon/site/main/hype_sintdata.png){width="60%"}</center>


Esses dados podem ser totalmente fict√≠cios ou derivados de dados reais com modifica√ß√µes, garantindo anonimato e privacidade.

[Segundo o prof. Leandro Coelho](https://www.gazetadopovo.com.br/parana/parana-tem-47-pesquisadores-mais-influentes-do-mundo/) podemos citar algumas potencialidades e limita√ß√µes de gera√ß√£o de dados sint√©ticos:

$\Rightarrow$ *Algumas potencialidades da gera√ß√£o de dados sint√©ticos:*

-   Preserva√ß√£o de privacidade: dados sint√©ticos eliminam a necessidade de compartilhar informa√ß√µes sens√≠veis ou pessoais. Permitem a conformidade com regulamentos como GDPR e LGPD ao substituir dados reais por vers√µes anonimizadas.

-   Aumento de dados: Aumenta o volume de dados em cen√°rios onde h√° dados limitados. Melhora o desempenho de modelos de aprendizado de m√°quina/profundo ao enriquecer o conjunto de treinamento com varia√ß√µes "realistas".

-   Simula√ß√£o de cen√°rios raros: Permite criar dados para eventos raros, como falhas em equipamentos, fraudes financeiras ou doen√ßas raras.

-   Redu√ß√£o de custos: Diminui a necessidade de coletar grandes quantidades de dados reais, que podem ser caros ou dif√≠ceis de obter.

-   Flexibilidade para testes: Facilita o desenvolvimento e teste de sistemas em ambientes controlados antes de serem implantados no mundo real.

-   Customiza√ß√£o de cen√°rios: Permite gerar dados com caracter√≠sticas espec√≠ficas, ajustados √†s necessidades do projeto.

-   Melhoria na qualidade dos dados: Corrige problemas de dados reais, tais como valores ausentes, erros ou enviesamento.

$\Rightarrow$ *Algumas limita√ß√µes da gera√ß√£o de dados sint√©ticos:*

-   Falta de complexidade do "mundo real": Dados sint√©ticos podem n√£o capturar completamente a complexidade e as nuances dos dados do mundo real, o que pode resultar em modelos que apresentam bom desempenho em simula√ß√µes, mas t√™m dificuldades com dados reais.

-   Quest√µes de qualidade e precis√£o: Dados sint√©ticos podem introduzir seus pr√≥prios vieses ou falhar em representar com precis√£o determinados grupos minorit√°rios ou casos extremos, o que pode levar a modelos tendenciosos.

-   Complexidade na gera√ß√£o: Gerar dados sint√©ticos de alta qualidade, especialmente usando t√©cnicas avan√ßadas de aprendizado profundo como redes geradoras advers√°rias (GANs) ou autoencoders variacionais (VAEs), pode ser computacionalmente caro e exigir um n√≠vel significativo de expertise.

<center>![](https://raw.githubusercontent.com/profrhozon/site/main/synt_data.png){width="80%"}</center>

::: panel-tabset
## Movimento Browniano Geom√©trico (MGB)

Uma abordagem robusta para gerar dados artificiais de s√©ries temporais financeiras √© utilizar o **Movimento Browniano Geom√©trico (MGB)**. Este m√©todo √© amplamente empregado para modelar a evolu√ß√£o dos pre√ßos de ativos, pois reproduz caracter√≠sticas importantes observadas em mercados reais, como:

-   **Distribui√ß√£o Log-Normal dos Pre√ßos:** Os pre√ßos gerados pelo MGB seguem uma distribui√ß√£o log-normal, o que √© compat√≠vel com a observa√ß√£o emp√≠rica de que os retornos dos ativos se distribuem normalmente.
-   **Drift (Tend√™ncia):** Representa o retorno m√©dio esperado do ativo.
-   **Volatilidade:** Mede a dispers√£o dos retornos e a incerteza no comportamento dos pre√ßos.
-   **Crescimento Exponencial:** A f√≥rmula incorpora um componente exponencial, essencial para refletir a acumula√ß√£o de retornos ao longo do tempo.

Mesmo sem um conjunto de dados hist√≥ricos, voc√™ pode definir par√¢metros te√≥ricos ou baseados em m√©dias de mercado (por exemplo, um drift anual de 10% e uma volatilidade anual de 20%) para simular s√©ries que se comportam de forma realista.

O MGB √© descrito pela seguinte equa√ß√£o diferencial estoc√°stica:

$$
dS_t = \mu S_t\, dt + \sigma S_t\, dW_t
$$

onde: - $S_t$ √© o pre√ßo do ativo no tempo $t$; - $\mu$ √© o drift (retorno m√©dio); - $\sigma$ √© a volatilidade do ativo; - $W_t$ representa o movimento browniano padr√£o (processo de Wiener).

A solu√ß√£o anal√≠tica dessa equa√ß√£o √© dada por:

$$
S_t = S_0 \exp\left\{ \left(\mu - \frac{1}{2}\sigma^2\right)t + \sigma W_t \right\}
$$

Para simula√ß√µes num√©ricas, considerando um intervalo de tempo discreto \$ \Delta t \$, a formula√ß√£o discreta do MGB √©:

$$
S_{t+\Delta t} = S_t \exp\left\{ \left(\mu - \frac{1}{2}\sigma^2\right)\Delta t + \sigma \sqrt{\Delta t}\,\epsilon_t \right\}
$$

onde $\epsilon_t$ √© uma vari√°vel aleat√≥ria com distribui√ß√£o normal padr√£o, ou seja, $\epsilon_t \sim \mathcal{N}(0,1)$.

### Por que o MGB √© √∫til?

-   **Simula√ß√£o Realista:** Ao utilizar par√¢metros que refletem a m√©dia do mercado, o MGB gera trajet√≥rias de pre√ßos que imitam o comportamento real dos ativos.
-   **Flexibilidade para M√∫ltiplos Ativos:** Pode ser facilmente adaptado para simular uma carteira de a√ß√µes. Se for necess√°rio, √© poss√≠vel incluir correla√ß√µes entre os ativos utilizando t√©cnicas como a decomposi√ß√£o de Cholesky.
-   **Base para Testes e An√°lises:** Os dados sint√©ticos gerados podem ser usados para testar estrat√©gias de trading, avaliar risco e realizar simula√ß√µes em portf√≥lios, mesmo quando dados hist√≥ricos reais n√£o est√£o dispon√≠veis.

### Implementa√ß√£o B√°sica do MGB em Python

A seguir, um exemplo de como gerar uma s√©rie temporal sint√©tica para uma carteira de a√ß√µes utilizando o MGB:

```{python}

import numpy as np
import pandas as pd

# Par√¢metros da simula√ß√£o
n_steps = 252  # N√∫mero de dias de negocia√ß√£o (aproximadamente um ano)
n_assets = 5   # N√∫mero de ativos na carteira
dt = 1/252     # Intervalo de tempo di√°rio

# Par√¢metros te√≥ricos (ou baseados em m√©dias de mercado)
mu = 0.1       # Retorno anual m√©dio (10%)
sigma = 0.2    # Volatilidade anual (20%)
S0 = 100       # Pre√ßo inicial para cada ativo

# Ancorando a semente para reprodutibilidade
np.random.seed(42)

# Gerando ru√≠dos aleat√≥rios (assumindo independ√™ncia entre os ativos)
epsilon = np.random.normal(0, 1, (n_steps, n_assets))

# Inicializando a matriz de pre√ßos
prices = np.zeros((n_steps + 1, n_assets))
prices[0] = S0

# Simula√ß√£o do MGB para cada ativo
for t in range(1, n_steps + 1):
    prices[t] = prices[t-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * epsilon[t-1])

# Cria√ß√£o de um DataFrame com os resultados
dates = pd.date_range(start='2020-01-01', periods=n_steps + 1, freq='B')
df = pd.DataFrame(prices, index=dates, columns=[f'Ativo_{i+1}' for i in range(n_assets)])

# Exibindo as primeiras linhas do DataFrame
print(df.head())

```

Para simular uma carteira onde os ativos possuem comportamentos correlacionados (mundo real, lembre-se que eu havia comentado que na realidade √© muito dif√≠cil montar um portf√≥lio com ativos com covari√¢ncia inversa), voc√™ pode:

1.  Definir uma Matriz de Correla√ß√£o: Especificar como os ativos se correlacionam entre si.

2.  Gerar Choques Correlacionados: Usar a decomposi√ß√£o de Cholesky para transformar ru√≠dos independentes em ru√≠dos correlacionados.

```{python}

# Exemplo de matriz de correla√ß√£o (matriz sim√©trica e definida positiva)
corr_matrix = np.array([
    [1.0, 0.8, 0.5, 0.3, 0.2],
    [0.8, 1.0, 0.6, 0.4, 0.3],
    [0.5, 0.6, 1.0, 0.7, 0.5],
    [0.3, 0.4, 0.7, 1.0, 0.6],
    [0.2, 0.3, 0.5, 0.6, 1.0]
])

# Decomposi√ß√£o de Cholesky para gerar uma matriz de transforma√ß√£o
L = np.linalg.cholesky(corr_matrix)

# Gerando ru√≠dos independentes
epsilon_indep = np.random.normal(0, 1, (n_steps, n_assets))

# Transformando os ru√≠dos independentes em ru√≠dos correlacionados
epsilon_corr = epsilon_indep @ L.T

# Simula√ß√£o do MGB utilizando os ru√≠dos correlacionados
prices_corr = np.zeros((n_steps + 1, n_assets))
prices_corr[0] = S0

for t in range(1, n_steps + 1):
    prices_corr[t] = prices_corr[t-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * epsilon_corr[t-1])

# Cria√ß√£o de um DataFrame com os pre√ßos correlacionados
df_corr = pd.DataFrame(prices_corr, index=dates, columns=[f'Ativo_{i+1}' for i in range(n_assets)])

# Exibindo as primeiras linhas do DataFrame com correla√ß√£o
print(df_corr.head())

```

Visualmente temos:

```{r fig.width=9, fig.height=9}

# Importar os dados do Python para o R
df_corr <- py$df_corr

# Converter o √≠ndice para uma coluna de data
df_corr <- df_corr |> 
  tibble::rownames_to_column(var = "date") |> 
  mutate(date = as.Date(date))

df_corr |> 
  pivot_longer(
    cols = -date,  # Todas as colunas, exceto "date"
    names_to = "Ativo",
    values_to = "Valor"
  ) |> 
  group_by(Ativo) |> 
  plot_time_series(
    .date_var = date,
    .value = Valor,
    .interactive = FALSE,  # Mude para TRUE para visualiza√ß√£o interativa
    .facet_ncol = 2,
    .smooth = FALSE
  ) +
  theme(
    strip.background = element_rect(fill = "white", colour = "white")
  )

```

O Movimento Browniano Geom√©trico (MGB) √© uma ferramenta poderosa para gerar dados sint√©ticos que asseguram os padr√µes comuns de comportamento dos pre√ßos de ativos financeiros. Ao utilizar esse m√©todo, √© poss√≠vel:

-   Simular trajet√≥rias de pre√ßos realistas baseadas em par√¢metros te√≥ricos (drift e volatilidade).
-   Estender a simula√ß√£o para m√∫ltiplos ativos, incorporando correla√ß√µes por meio da decomposi√ß√£o de Cholesky.
-   Fornecer uma base robusta para testes de estrat√©gias, avalia√ß√µes de risco e simula√ß√µes de portf√≥lio mesmo na aus√™ncia de dados hist√≥ricos.
-   Essa abordagem garante que o conjunto de dados artificial gerado mant√©m as caracter√≠sticas essenciais dos mercados reais, permitindo an√°lises consistentes e confi√°veis.

## Simula√ß√£o de Processos Estoc√°sticos

üìä Melhor para: Capturar padr√µes realistas de volatilidade e impacto de eventos externos.

üí° Vantagem: Modela propriedades emp√≠ricas observadas nos pre√ßos dos ativos financeiros.

**Processo de Heston**: Extens√£o do MGB que incorpora variabilidade na volatilidade ao longo do tempo, melhorando a modelagem de risco e retornos extremos.

**Processo de Ornstein-Uhlenbeck**: Modela revers√£o √† m√©dia, √∫til para s√©ries financeiras que exibem tend√™ncias estacion√°rias.

**Processo Hawkes:** Modela eventos que influenciam fortemente o mercado (ex: "Efeito Manada" e choques de liquidez).


```{python}

import numpy as np
import pandas as pd
import sdeint  # Biblioteca para simula√ß√£o de processos estoc√°sticos no Python

# Defini√ß√µes gerais
np.random.seed(42)
dias = 252  # 1 ano de preg√£o
ativos = ["Ativo A", "Ativo B", "Ativo C", "Ativo D", "Ativo E"]
precos_iniciais = [100, 50, 200, 30, 150]
datas = pd.date_range(start="2025-01-01", periods=dias, freq="B")

# ---------------------------
# 1Ô∏è‚É£ PROCESSO DE HESTON (VOLATILIDADE ESTOC√ÅSTICA)
# ---------------------------

def heston_simulacao(S0, v0, mu, kappa, theta, sigma, rho, T, N):
    dt = T / N
    S = np.zeros(N)
    v = np.zeros(N)
    S[0], v[0] = S0, v0

    for t in range(1, N):
        dW_S = np.random.normal(0, np.sqrt(dt))
        dW_v = rho * dW_S + np.sqrt(1 - rho**2) * np.random.normal(0, np.sqrt(dt))

        v[t] = np.abs(v[t-1] + kappa * (theta - v[t-1]) * dt + sigma * np.sqrt(v[t-1]) * dW_v)
        S[t] = S[t-1] * np.exp((mu - 0.5 * v[t-1]) * dt + np.sqrt(v[t-1]) * dW_S)

    return S

df_heston = pd.DataFrame({"Data": datas})
for i, ativo in enumerate(ativos):
    df_heston[ativo] = heston_simulacao(precos_iniciais[i], 0.04, 0.1, 2, 0.04, 0.3, -0.7, 1, dias)

# ---------------------------
# 2Ô∏è‚É£ PROCESSO DE ORNSTEIN-UHLENBECK (REVERS√ÉO √Ä M√âDIA)
# ---------------------------

def ornstein_uhlenbeck_simulacao(S0, theta, mu, sigma, T, N):
    dt = T / N
    S = np.zeros(N)
    S[0] = S0
    for t in range(1, N):
        dW = np.random.normal(0, np.sqrt(dt))
        S[t] = S[t-1] + theta * (mu - S[t-1]) * dt + sigma * dW
    return S

df_ou = pd.DataFrame({"Data": datas})
for i, ativo in enumerate(ativos):
    df_ou[ativo] = ornstein_uhlenbeck_simulacao(precos_iniciais[i], 0.5, precos_iniciais[i] * 1.05, 1.5, 1, dias)

# ---------------------------
# 3Ô∏è‚É£ PROCESSO DE HAWKES (EVENTOS QUE IMPACTAM O MERCADO)
# ---------------------------

def hawkes_process(T, mu, alpha, beta):
    times = []
    t = 0
    while t < T:
        lambda_t = mu + alpha * sum(np.exp(-beta * (t - np.array(times))))
        w = np.random.exponential(1 / lambda_t)
        t += w
        if t < T:
            times.append(t)
    return times

df_hawkes = pd.DataFrame({"Data": datas})
for i, ativo in enumerate(ativos):
    eventos = hawkes_process(dias, mu=0.5, alpha=0.8, beta=1.2)
    impactos = np.zeros(dias)
    for evento in eventos:
        idx = min(int(evento), dias - 1)
        impactos[idx] += np.random.uniform(-2, 2)
    df_hawkes[ativo] = precos_iniciais[i] + np.cumsum(impactos)


```

Graficamente temos:

```{r fig.width=9, fig.height=9}

library(tidyverse)
library(timetk)

# Importar os dados gerados no Python
df_heston <- py$df_heston
df_ou <- py$df_ou
df_hawkes <- py$df_hawkes

# Converter a coluna "Data" para formato Date no R
df_heston <- df_heston |> mutate(Data = as.Date(Data))
df_ou <- df_ou |> mutate(Data = as.Date(Data))
df_hawkes <- df_hawkes |> mutate(Data = as.Date(Data))

# Fun√ß√£o para plotar s√©ries temporais
plot_series <- function(df, title) {
  df |> 
    pivot_longer(cols = -Data, names_to = "Ativo", values_to = "Valor") |> 
    group_by(Ativo) |> 
    plot_time_series(
      .date_var = Data,
      .value = Valor,
      .interactive = FALSE,
      .facet_ncol = 2,
      .smooth = FALSE
    ) +
    labs(title = title) +
    theme(strip.background = element_rect(fill = "white", colour = "white"))
}

# üìä Plotar os diferentes modelos
plot_series(df_heston, "üìà Simula√ß√£o de Pre√ßos com Processo de Heston")
plot_series(df_ou, "üìâ Simula√ß√£o com Processo de Ornstein-Uhlenbeck (Revers√£o √† M√©dia)")
plot_series(df_hawkes, "üí• Simula√ß√£o com Processo de Hawkes (Eventos Impactantes)")

```

üöÄ Bibliotecas:

üì¶ ``sdeint`` (Simula√ß√£o de processos estoc√°sticos no Python)

## Usando uma distribui√ß√£o log-normal

Na pr√°tica podemos fazer uso de diversas t√©cnicas estat√≠sticas para gerar dados sint√©ticos, incluindo gera√ß√£o de distribui√ß√µes como normal, exponencial, uniforme, binomial, Poisson, beta, gama, lognormal e geom√©trica. E assim, obviamente adaptarmos para gera√ß√£o de dados sint√©ticos de s√©ries temporais de diferentes padr√µes.

Para gerar dados sint√©ticos de s√©ries temporais financeiras com t√©cnicas relacionadas ao que encontramos na literatura especializada, voc√™ pode:

$\Rightarrow$ Usar a Distribui√ß√£o Lognormal:

-   Muitas s√©ries temporais financeiras, como retornos de ativos e pre√ßos de a√ß√µes, seguem distribui√ß√µes muito pr√≥ximas a lognormais.
-   Voc√™ pode gerar dados sint√©ticos de retornos di√°rios e, a partir disso, reconstruir pre√ßos sint√©ticos.

```{python}

# Par√¢metros
np.random.seed(42)  # Ancorando a semente para reprodutibilidade
dias = 252  # Um ano de preg√£o
ativos = ["Ativo A", "Ativo B", "Ativo C", "Ativo D", "Ativo E"]
precos_iniciais = [100, 50, 200, 30, 150]  # Pre√ßo inicial de cada ativo

# Par√¢metros individuais para cada ativo
mu = [0.0005, 0.0003, 0.0007, 0.0002, 0.0006]  # Retorno m√©dio di√°rio
sigma = [0.02, 0.025, 0.015, 0.03, 0.018]  # Volatilidade di√°ria

# Criando DataFrame
datas = pd.date_range(start="2020-01-01", periods=dias, freq="B")
df_sintetico = pd.DataFrame({"Data": datas})

# Gerando s√©ries temporais sint√©ticas para cada ativo
for i, ativo in enumerate(ativos):
    retornos = np.random.lognormal(mean=mu[i], sigma=sigma[i], size=dias) - 1
    precos = precos_iniciais[i] * np.cumprod(1 + retornos)
    df_sintetico[ativo] = precos

```

Graficamente temos:

```{r fig.width=9, fig.height=9}

# Importar os dados gerados no Python
df_sintetico <- py$df_sintetico

# Converter a coluna "Data" para formato Date no R
df_sintetico <- df_sintetico |> 
  rename(date = Data) |> 
  mutate(date = as.Date(date))

df_sintetico |> 
  pivot_longer(
    cols = -date,  # Todas as colunas, exceto "date"
    names_to = "Ativo",
    values_to = "Valor"
  ) |> 
  group_by(Ativo) |> 
  plot_time_series(
    .date_var = date,
    .value = Valor,
    .interactive = FALSE,  # Mude para TRUE para visualiza√ß√£o interativa
    .facet_ncol = 2,
    .smooth = FALSE
  ) +
  theme(
    strip.background = element_rect(fill = "white", colour = "white")
  )

```

## Gerar S√©ries Temporais com Ru√≠do Gaussiano

Para simular s√©ries temporais financeiras de forma simples, voc√™ pode modelar um processo de passeio aleat√≥rio com tend√™ncia, mais conhecido como Random Walk with drift:

```{python}

# Par√¢metros
np.random.seed(42)  # Ancorando a semente para reprodutibilidade
dias = 252  # Um ano de preg√£o
ativos = ["Ativo A", "Ativo B", "Ativo C", "Ativo D", "Ativo E"]
precos_iniciais = [100, 50, 200, 30, 150]  # Pre√ßo inicial de cada ativo

# Par√¢metros individuais para cada ativo
tendencias = [0.0003, 0.0001, 0.0005, -0.0002, 0.0004]  # Tend√™ncia para Random Walk
sigma = [0.02, 0.025, 0.015, 0.03, 0.018]  # Volatilidade di√°ria

# Criando DataFrame
datas = pd.date_range(start="2020-01-01", periods=dias, freq="B")
df_gaussiano = pd.DataFrame({"Data": datas})

# Gerando s√©ries temporais sint√©ticas para cada ativo
for i, ativo in enumerate(ativos):
    ruido = np.random.normal(loc=0, scale=sigma[i], size=dias)
    precos_gaussiano = np.cumsum(tendencias[i] + ruido) + precos_iniciais[i]
    df_gaussiano[ativo] = precos_gaussiano

```

Gr√°ficamente, temos:

```{r fig.width=9, fig.height=9}

# Importar os dados gerados no Python
df_gaussiano <- py$df_gaussiano

# Converter a coluna "Data" para formato Date no R
df_gaussiano <- df_gaussiano |> 
  rename(date = Data) |> 
  mutate(date = as.Date(date))

df_gaussiano |> 
  pivot_longer(
    cols = -date,  # Todas as colunas, exceto "date"
    names_to = "Ativo",
    values_to = "Valor"
  ) |> 
  group_by(Ativo) |> 
  plot_time_series(
    .date_var = date,
    .value = Valor,
    .interactive = FALSE,  # Mude para TRUE para visualiza√ß√£o interativa
    .facet_ncol = 2,
    .smooth = FALSE
  ) +
  theme(
    strip.background = element_rect(fill = "white", colour = "white")
  )

```

## Gerando dataset com GAN

As Redes Adversariais Generativas (GANs) s√£o uma abordagem mais sofisticada para gerar s√©ries temporais sint√©ticas. Para s√©ries temporais financeiras, pode-se usar TimeGAN, que preserva padr√µes temporais complexos.

Aqui est√° um c√≥digo b√°sico usando PyTorch para treinar uma GAN simples em dados financeiros sint√©ticos.

C√≥digo GAN para S√©ries Temporais

Aqui, treinamos uma GAN para gerar s√©ries temporais financeiras sint√©ticas para os 5 ativos.

```{python}

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Par√¢metros
dias = 252
ativos = ["Ativo A", "Ativo B", "Ativo C", "Ativo D", "Ativo E"]
precos_iniciais = [100, 50, 200, 30, 150]
z_dim = 100
lr = 0.001
epochs = 1000
batch_size = 32

# Criando dataset sint√©tico com GAN
df_carteira_gan = pd.DataFrame({"Data": pd.date_range(start="2020-01-01", periods=dias, freq="B")})

# Criando Gerador e Discriminador
class Generator(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, output_dim)
        )
    
    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self, input_dim):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        return self.model(x)

# Criando GAN para cada ativo
for ativo, preco_inicial in zip(ativos, precos_iniciais):
    print(f"Treinando GAN para {ativo}...")
    
    # Criando dados reais simulados (caminho aleat√≥rio com tend√™ncia)
    tendencia = np.random.uniform(-0.0005, 0.0008)
    ruido = np.random.normal(0, 0.02, dias)
    serie_real = np.cumsum(tendencia + ruido) + preco_inicial
    serie_torch = torch.tensor(serie_real, dtype=torch.float32).view(-1, 1)

    # Instanciando modelos
    generator = Generator(z_dim, 1)
    discriminator = Discriminator(1)

    # Fun√ß√£o de perda e otimizadores
    criterion = nn.BCELoss()
    optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr)
    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)

    # Treinamento da GAN
    for epoch in range(epochs):
        noise = torch.randn((batch_size, z_dim))
        fake_data = generator(noise)
        real_samples = serie_torch[torch.randint(0, len(serie_torch), (batch_size,))]

        optimizer_D.zero_grad()
        real_loss = criterion(discriminator(real_samples), torch.ones((batch_size, 1)))
        fake_loss = criterion(discriminator(fake_data.detach()), torch.zeros((batch_size, 1)))
        d_loss = real_loss + fake_loss
        d_loss.backward()
        optimizer_D.step()

        optimizer_G.zero_grad()
        g_loss = criterion(discriminator(fake_data), torch.ones((batch_size, 1)))
        g_loss.backward()
        optimizer_G.step()

        if epoch % 200 == 0:
            print(f"{ativo} | Epoch {epoch}: Loss D={d_loss.item():.4f}, Loss G={g_loss.item():.4f}")

    # Gerando S√©rie Sint√©tica
    noise = torch.randn((dias, z_dim))
    serie_sintetica = generator(noise).detach().numpy().flatten()
    df_carteira_gan[ativo] = serie_sintetica

# Plotando os ativos gerados por GAN
#plt.figure(figsize=(12,6))
#for ativo in ativos:
#    plt.plot(df_carteira_gan["Data"], df_carteira_gan[ativo], label=ativo)
#plt.legend()
#plt.title("S√©ries Temporais Sint√©ticas para 5 Ativos (GAN)")
#plt.xlabel("Data")
#plt.ylabel("Pre√ßo")
#plt.show()

```

```{r fig.width=9, fig.height=9}

# Importar os dados gerados pela GAN do Python para o R
df_carteira_gan <- py$df_carteira_gan

# Converter a coluna "Data" para formato Date no R
df_carteira_gan <- df_carteira_gan |> 
  rename(date = Data) |> 
  mutate(date = as.Date(date))

df_carteira_gan |> 
  pivot_longer(
    cols = -date,  # Todas as colunas, exceto "date"
    names_to = "Ativo",
    values_to = "Valor"
  ) |> 
  group_by(Ativo) |> 
  plot_time_series(
    .date_var = date,
    .value = Valor,
    .interactive = FALSE,  # Mude para TRUE para visualiza√ß√£o interativa
    .facet_ncol = 2,
    .smooth = FALSE
  ) +
  theme(
    strip.background = element_rect(fill = "white", colour = "white")
  )


```

## AutoEncoders Variacionais (VAE)

<mark> Desativado nas c√©lulas em fun√ß√£o do tempo de execu√ß√£o </mark>

-   O VAE aprende a codificar s√©ries temporais em um espa√ßo latente e gera novas s√©ries a partir dessa distribui√ß√£o.
-   Ele √© √∫til para gerar dados sint√©ticos que preservam padr√µes temporais complexos sem depender de distribui√ß√µes pr√©-definidas.

```{python}
#| eval: false

# O comando abaixo da c√©lula Python #| eval: false desativa a execu√ß√£o da c√©lula em quest√£o

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, Dense, Lambda
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
import matplotlib.pyplot as plt

# Ancorando a semente para reprodutibilidade
np.random.seed(42)
tf.random.set_seed(42)

# Par√¢metros
dias = 252  # Um ano de preg√£o
ativos = ["Ativo A", "Ativo B", "Ativo C", "Ativo D", "Ativo E"]
precos_iniciais = [100, 50, 200, 30, 150]
tendencias = [0.0005, 0.0002, 0.0008, -0.0003, 0.0006]
volatilidades = [0.02, 0.03, 0.015, 0.025, 0.018]

# Criando dataset inicial de s√©ries reais simuladas
datas = pd.date_range(start="2025-01-01", periods=dias, freq="B")
df_real = pd.DataFrame({"Data": datas})

series_real = []
for i in range(len(ativos)):
    ruido = np.random.normal(loc=0, scale=volatilidades[i], size=dias)
    serie = np.cumsum(tendencias[i] + ruido) + precos_iniciais[i]
    series_real.append(serie)
    df_real[ativos[i]] = serie

# Normalizando os dados para o intervalo [0,1]
series_real = np.array(series_real)
series_min = series_real.min(axis=1, keepdims=True)
series_max = series_real.max(axis=1, keepdims=True)
series_real_norm = (series_real - series_min) / (series_max - series_min)

# Definindo o VAE
original_dim = dias  # N√∫mero de dias de negocia√ß√£o
latent_dim = 2  # Dimens√£o do espa√ßo latente
intermediate_dim = 64  # Camada oculta intermedi√°ria

# Encoder
inputs = Input(shape=(original_dim,))
h = Dense(intermediate_dim, activation="relu")(inputs)
z_mean = Dense(latent_dim)(h)
z_log_var = Dense(latent_dim)(h)

# Amostragem usando reparametriza√ß√£o
def sampling(args):
    z_mean, z_log_var = args
    batch = K.shape(z_mean)[0]
    dim = K.int_shape(z_mean)[1]
    epsilon = K.random_normal(shape=(batch, dim), mean=0., stddev=1.0)
    return z_mean + K.exp(0.5 * z_log_var) * epsilon

z = Lambda(sampling)([z_mean, z_log_var])

# Decoder
decoder_h = Dense(intermediate_dim, activation="relu")
decoder_mean = Dense(original_dim, activation="sigmoid")
h_decoded = decoder_h(z)
outputs = decoder_mean(h_decoded)

# Defini√ß√£o do modelo VAE
vae = Model(inputs, outputs)

# Fun√ß√£o de perda correta
reconstruction_loss = keras.losses.mean_squared_error(inputs, outputs)
reconstruction_loss = K.sum(reconstruction_loss)  # Evita NoneType Error
kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)

vae_loss = K.mean(reconstruction_loss + kl_loss)
vae.add_loss(vae_loss)  # Adiciona corretamente ao modelo
vae.compile(optimizer="adam")

# Treinamento do VAE
vae.fit(series_real_norm, epochs=300, batch_size=5, verbose=1)

# Gerando novas s√©ries sint√©ticas
latent_samples = np.random.normal(size=(len(ativos), latent_dim))
decoder_input = keras.Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)

series_sinteticas_norm = generator.predict(latent_samples)

# Convertendo de volta para a escala original
series_sinteticas = series_sinteticas_norm * (series_max - series_min) + series_min

# Criando DataFrame com os dados gerados
df_vae = pd.DataFrame(series_sinteticas.T, index=datas, columns=ativos)
df_vae.reset_index(inplace=True)
df_vae.rename(columns={"index": "Data"}, inplace=True)


```

Graficamente ele fica:

```{r fig.width=9, fig.height=9, eval=FALSE}

# O comando , eval=FALSE desativa a execu√ß√£o da c√©lula R em quest√£o

library(tidyverse)
library(timetk)

# Importar os dados gerados no Python
df_vae <- py$df_vae

# Converter a coluna "Data" para formato Date no R
df_vae <- df_vae |> 
  rename(date = Data) |> 
  mutate(date = as.Date(date))

# Visualizar os dados sint√©ticos do VAE
df_vae |> 
  pivot_longer(
    cols = -date,  # Todas as colunas, exceto "date"
    names_to = "Ativo",
    values_to = "Valor"
  ) |> 
  group_by(Ativo) |> 
  plot_time_series(
    .date_var = date,
    .value = Valor,
    .interactive = FALSE,  # Mude para TRUE para visualiza√ß√£o interativa
    .facet_ncol = 2,
    .smooth = FALSE
  ) +
  theme(
    strip.background = element_rect(fill = "white", colour = "white")
  )

```


## TimeGAN

O Time-Series Generative Adversarial Network (TimeGAN) √© um modelo de redes neurais profundas projetado especificamente para gera√ß√£o de s√©ries temporais sint√©ticas. Ele combina autoencoders, redes adversariais generativas (GANs) e redes recorrentes (RNNs/LSTMs) para aprender e gerar dados sint√©ticos que preservam tanto as distribui√ß√µes estat√≠sticas quanto as depend√™ncias temporais dos dados reais.

```{python}
#| eval: false


import tensorflow as tf
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt

from timegan import TimeGAN

# Ancorando a semente para reprodutibilidade
np.random.seed(42)
tf.random.set_seed(42)

# Par√¢metros
dias = 252  # Um ano de preg√£o
ativos = ["Ativo A", "Ativo B", "Ativo C", "Ativo D", "Ativo E"]
precos_iniciais = [100, 50, 200, 30, 150]
tendencias = [0.0005, 0.0002, 0.0008, -0.0003, 0.0006]
volatilidades = [0.02, 0.03, 0.015, 0.025, 0.018]

# Criando dataset inicial de s√©ries reais simuladas
datas = pd.date_range(start="2025-01-01", periods=dias, freq="B")
df_real = pd.DataFrame({"Data": datas})

series_real = []
for i in range(len(ativos)):
    ruido = np.random.normal(loc=0, scale=volatilidades[i], size=dias)
    serie = np.cumsum(tendencias[i] + ruido) + precos_iniciais[i]
    series_real.append(serie)
    df_real[ativos[i]] = serie

# Normalizando os dados para o intervalo [0,1]
series_real = np.array(series_real).T  # Transpor para (dias, ativos)
series_min = series_real.min(axis=0, keepdims=True)
series_max = series_real.max(axis=0, keepdims=True)
series_real_norm = (series_real - series_min) / (series_max - series_min)

# Configura√ß√£o do TimeGAN
timegan = TimeGAN(epochs=500, batch_size=32, latent_dim=5)

# Treinando o TimeGAN com os dados normalizados
timegan.fit(series_real_norm)

# Gerando dados sint√©ticos com TimeGAN
series_sinteticas_norm = timegan.generate(n_samples=dias)

# Convertendo de volta para a escala original
series_sinteticas = series_sinteticas_norm * (series_max - series_min) + series_min

# Criando DataFrame com os dados gerados
df_timegan = pd.DataFrame(series_sinteticas, index=datas, columns=ativos)
df_timegan.reset_index(inplace=True)
df_timegan.rename(columns={"index": "Data"}, inplace=True)


```


Graficamente

```{r fig.width=9, fig.height=9, eval=FALSE}

library(tidyverse)
library(timetk)

# Importar os dados gerados no Python
df_timegan <- py$df_timegan

# Converter a coluna "Data" para formato Date no R
df_timegan <- df_timegan |> 
  rename(date = Data) |> 
  mutate(date = as.Date(date))

# Visualizar os dados sint√©ticos do TimeGAN
df_timegan |> 
  pivot_longer(
    cols = -date,  # Todas as colunas, exceto "date"
    names_to = "Ativo",
    values_to = "Valor"
  ) |> 
  group_by(Ativo) |> 
  plot_time_series(
    .date_var = date,
    .value = Valor,
    .interactive = FALSE,  # Mude para TRUE para visualiza√ß√£o interativa
    .facet_ncol = 2,
    .smooth = FALSE
  ) +
  theme(
    strip.background = element_rect(fill = "white", colour = "white")
  )


```


## RNNs, LSTMs e GRUs

- Treinaremos um modelo de LSTM para aprender padr√µes de s√©ries temporais financeiras.
- Depois, geramos novas s√©ries sint√©ticas com a LSTM treinada.

```{python}
#| eval: false

# Celula inativada com o comando no #| eval: false no incio pelo tempo demorado de execu√ß√£o

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# üìå Fixando a semente para reprodutibilidade
np.random.seed(42)
torch.manual_seed(42)

# üìå Par√¢metros
dias = 500  
ativos = ["Ativo A", "Ativo B", "Ativo C", "Ativo D", "Ativo E"]
precos_iniciais = [100, 50, 200, 30, 150]
seq_length = 50  # üî• Aumentando para capturar mais padr√µes
num_simulacoes = 5  # üî• Geraremos m√∫ltiplas s√©ries e tiramos a m√©dia

# üî• Simula√ß√£o de s√©ries financeiras com mais varia√ß√£o
tendencias = [0.0005, 0.0002, 0.0008, -0.0003, 0.0006]
volatilidades = [0.02, 0.03, 0.015, 0.025, 0.018]

# Criando DataFrame de s√©ries reais simuladas
datas = pd.date_range(start="2025-01-01", periods=dias, freq="B")
df_real = pd.DataFrame({"Data": datas})

series_real = []
for i in range(len(ativos)):
    ruido = np.random.normal(loc=0, scale=volatilidades[i], size=dias)
    serie = np.cumsum(tendencias[i] + ruido) + precos_iniciais[i]
    series_real.append(serie)
    df_real[ativos[i]] = serie

# üìå Normalizando os dados entre 0 e 1
series_real = np.array(series_real).T
series_min = series_real.min(axis=0)
series_max = series_real.max(axis=0)
series_real_norm = (series_real - series_min) / (series_max - series_min)

# Criando dados para treino (janelas de tempo)
def create_sequences(data, seq_length):
    sequences, targets = [], []
    for i in range(len(data) - seq_length):
        sequences.append(data[i : i + seq_length])
        targets.append(data[i + seq_length])
    return np.array(sequences), np.array(targets)

X, y = create_sequences(series_real_norm, seq_length)

# Convertendo para tensores PyTorch
X_tensor = torch.tensor(X, dtype=torch.float32)
y_tensor = torch.tensor(y, dtype=torch.float32)

# Criando DataLoader
dataset = TensorDataset(X_tensor, y_tensor)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# üìå Modelo LSTM Melhorado üî•
class AdvancedLSTM(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):
        super(AdvancedLSTM, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout, bidirectional=True)
        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiplicado por 2 por ser bidirectional
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        out = self.dropout(lstm_out[:, -1])
        return self.fc(out)

# üìå Ajustando hiperpar√¢metros üî•
input_dim = len(ativos)
hidden_dim = 256  # üî• Aumentando capacidade
output_dim = len(ativos)
num_layers = 4  # üî• Aumentando camadas
dropout = 0.3  # üî• Dropout mais alto

# Criando modelo
model = AdvancedLSTM(input_dim, hidden_dim, output_dim, num_layers, dropout)

# üìå Treinamento com mais √©pocas e regulariza√ß√£o üî•
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.0005)  # üî• Taxa de aprendizado menor
epochs = 300  # üî• Aumentando epochs

for epoch in range(epochs):
    total_loss = 0
    for batch_X, batch_y in dataloader:
        optimizer.zero_grad()
        output = model(batch_X)
        loss = criterion(output, batch_y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    
    if (epoch + 1) % 25 == 0:
        print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}")

# üìå Gerando m√∫ltiplas simula√ß√µes üî•
def generate_synthetic_data(model, initial_seq, num_steps=252, num_sim=5):
    model.eval()
    all_sims = []
    for _ in range(num_sim):
        generated_data = []
        input_seq = torch.tensor(initial_seq, dtype=torch.float32).unsqueeze(0)

        for _ in range(num_steps):
            with torch.no_grad():
                next_step = model(input_seq).detach().numpy()
            generated_data.append(next_step)
            input_seq = torch.cat([input_seq[:, 1:], torch.tensor(next_step).unsqueeze(0)], dim=1)

        all_sims.append(np.array(generated_data).squeeze())

    return np.mean(all_sims, axis=0)  # üî• Tiramos a m√©dia das simula√ß√µes para suavizar padr√µes

# Pegando a √∫ltima janela de dados reais para iniciar a gera√ß√£o
initial_seq = series_real_norm[-seq_length:]
generated_series_norm = generate_synthetic_data(model, initial_seq)

# üìå Convertendo de volta para a escala original
generated_series = generated_series_norm * (series_max - series_min) + series_min

# Criando DataFrame com os dados gerados
df_lstm_advanced = pd.DataFrame(generated_series, index=datas[:len(generated_series)], columns=ativos)
df_lstm_advanced.reset_index(inplace=True)
df_lstm_advanced.rename(columns={"index": "Data"}, inplace=True)


```


Graficamente:

```{r fig.width=9, fig.height=9, eval=FALSE}

# Se quiser executar essa celula retire do chunk o argumento ,eval=FALSE

# Importar os dados gerados no Python
df_lstm <- py$df_lstm

# Converter a coluna "Data" para formato Date no R
df_lstm <- df_lstm |> 
  rename(date = Data) |> 
  mutate(date = as.Date(date))

# üìä Visualizar os dados sint√©ticos da LSTM
df_lstm |> 
  pivot_longer(
    cols = -date,  # Todas as colunas, exceto "date"
    names_to = "Ativo",
    values_to = "Valor"
  ) |> 
  group_by(Ativo) |> 
  plot_time_series(
    .date_var = date,
    .value = Valor,
    .interactive = FALSE,  # Mude para TRUE para visualiza√ß√£o interativa
    .facet_ncol = 2,
    .smooth = FALSE
  ) +
  theme(
    strip.background = element_rect(fill = "white", colour = "white")
  )


```



:::

# üìä Compara√ß√£o dos M√©todos de Gera√ß√£o de Dados Sint√©ticos

Cada uma das abordagens apresentadas para a gera√ß√£o de s√©ries temporais sint√©ticas possui vantagens e desvantagens. A tabela a seguir compara os m√©todos discutidos:

| M√©todo | Caracter√≠sticas | Vantagens | Desvantagens | Melhor Uso |
|--------|---------------|-----------|--------------|------------|
| **Movimento Browniano Geom√©trico (MGB)** | Baseado em um processo estoc√°stico com retorno e volatilidade constantes | Simples de implementar e amplamente utilizado | N√£o captura mudan√ßas de volatilidade e choques de mercado | Modelagem b√°sica de pre√ßos de ativos financeiros |
| **Distribui√ß√£o Log-normal** | Gera retornos di√°rios e reconstr√≥i pre√ßos sint√©ticos | Captura a distribui√ß√£o emp√≠rica dos retornos | N√£o incorpora depend√™ncias temporais | Simula√ß√£o de s√©ries financeiras individuais |
| **Ru√≠do Gaussiano** | Modela s√©ries como processos de ru√≠do branco com tend√™ncia | F√°cil de calibrar | N√£o reflete efeitos de autocorrela√ß√£o | Simula√ß√µes de s√©ries estacion√°rias e processos aleat√≥rios |
| **Processo de Heston** | Modela volatilidade estoc√°stica ao longo do tempo | Captura din√¢mica realista de volatilidade | Complexidade computacional elevada | Precifica√ß√£o de op√ß√µes e avalia√ß√£o de risco |
| **Processo de Ornstein-Uhlenbeck** | Modela revers√£o √† m√©dia | Adequado para ativos estacion√°rios | N√£o reflete grandes varia√ß√µes de mercado | Modelagem de taxas de juros e commodities |
| **Processo de Hawkes** | Modela impactos repentinos e eventos ex√≥genos | Captura choques de liquidez e "efeito manada" | Requer calibra√ß√£o cuidadosa | An√°lise de impacto de not√≠cias no mercado |
| **GANs (Redes Adversariais Generativas)** | Redes neurais advers√°rias geram s√©ries temporais | Capacidade de aprender padr√µes temporais complexos | Treinamento complexo e propenso a instabilidade | Gera√ß√£o de s√©ries realistas para testes de modelos de trading |
| **Autoencoders Variacionais (VAE)** | Compacta s√©ries no espa√ßo latente e reconstr√≥i | Captura padr√µes de longo prazo | Pode perder variabilidade estoc√°stica | Gera√ß√£o de s√©ries sint√©ticas para an√°lise de risco |
| **TimeGAN** | Aprendizagem profunda com mem√≥ria temporal | Mant√©m padr√µes estat√≠sticos e temporais | Alto custo computacional e necessidade de grande volume de dados | Modelagem realista de s√©ries financeiras complexas |
| **RNNs, LSTMs e GRUs** | Modelos baseados em redes neurais recorrentes | Capturam depend√™ncias temporais e padr√µes ocultos | Treinamento complexo e demanda muitos dados | Simula√ß√£o de s√©ries financeiras com mem√≥ria temporal |

---


### üìå Escolhendo o M√©todo Adequado

A escolha do m√©todo ideal para gerar dados sint√©ticos depende do objetivo da an√°lise:

-   **Se o foco for replicar padr√µes estat√≠sticos gerais do mercado**, o **MGB** pode ser suficiente.
-   **Se for necess√°rio capturar efeitos de retornos assim√©tricos e volatilidade vari√°vel**, a **distribui√ß√£o lognormal** pode ser uma boa alternativa.
-   **Se for apenas um teste de modelagem sem preocupa√ß√£o com estrutura√ß√£o realista**, um **random walk com drift** pode funcionar.
-   **Se a necessidade for criar s√©ries sint√©ticas que preservem as propriedades temporais e padr√µes estruturais reais dos mercados financeiros**, ent√£o **GANs** s√£o a melhor escolha.

üìå **Resumo:**
- M√©todos estoc√°sticos como **MGB, Heston e OU** s√£o ideais para modelagem financeira te√≥rica.
- **TimeGAN e RNNs** s√£o mais realistas, mas exigem alto poder computacional.
- **GANs e VAEs** s√£o boas alternativas para replicar padr√µes complexos.
- **Processos Hawkes** s√£o ideais para capturar eventos ex√≥genos como choques de mercado.

### üî• Conclus√£o

Os m√©todos de gera√ß√£o de dados sint√©ticos apresentados oferecem ferramentas poderosas para an√°lise e modelagem de s√©ries temporais financeiras. Dependendo da aplica√ß√£o, pode ser necess√°rio combinar diferentes abordagens ou escolher aquela que melhor se adapta ao problema. A capacidade de gerar dados sint√©ticos n√£o apenas permite a experimenta√ß√£o sem a necessidade de dados hist√≥ricos reais, mas tamb√©m abre novas possibilidades para pesquisa, desenvolvimento de algoritmos e an√°lise de risco no mercado financeiro.

:::

## üì¢ Not√≠cias e Publica√ß√µes sobre Dados Sint√©ticos

### üóìÔ∏è 04/07/2024 - Gartner Revela o Futuro da IA Generativa

-   At√© 2026, **75% das empresas** usar√£o IA generativa para criar dados sint√©ticos de clientes.\
-   Segundo a consultoria **McKinsey**, o uso de dados sint√©ticos pode acelerar o desenvolvimento de IA em **at√© 50%**.\
-   A **PwC** estima que o uso de dados sint√©ticos pode reduzir os custos de desenvolvimento de software em **at√© 30%**.\
    üîó [Leia mais](https://imasters.com.br/generative-ai/gartner-revela-o-futuro-da-ia-generativa)

------------------------------------------------------------------------

### üóìÔ∏è 23/01/2023 - MIT Management Sloan School: O que s√£o dados sint√©ticos ‚Äî e como podem ajudar competitivamente?

-   **Dados sint√©ticos**, que se assemelham a conjuntos de dados reais, **n√£o comprometem a privacidade**, permitindo que empresas compartilhem dados e criem algoritmos com mais facilidade.\
    üîó [Leia mais](https://mitsloan.mit.edu/ideas-made-to-matter/what-synthetic-data-and-how-can-it-help-you-competitively)

------------------------------------------------------------------------

### üèõÔ∏è EDPS - European Data Protection Supervisor

-   **Synthetic Dice**: estudo sobre o impacto dos dados sint√©ticos na privacidade e seguran√ßa dos dados na Europa.\
    üîó [Leia mais](https://www.edps.europa.eu/press-publications/publications/techsonar/synthetic-data_en)

### üìë Publica√ß√£o EDPS ‚Äì Multipurpose Synthetic Population for Policy Applications

-   **Autores**: Hradec, J., Craglia, M., Di Leo, M., De Nigris, S., Ostlaender, N. e Nicholson, N.\
-   **Publica√ß√£o**: EUR 31116 EN, Publications Office of the European Union, 2022\
-   **Resumo**: Uso de popula√ß√µes sint√©ticas para formula√ß√£o de pol√≠ticas p√∫blicas.\
    üîó [Leia o estudo](https://publications.jrc.ec.europa.eu/repository/handle/JRC128595)

------------------------------------------------------------------------

### üóìÔ∏è 19/02/2024 - EUA: Synthetic Data na Legisla√ß√£o dos EUA e da UE

-   **Discuss√£o legal** sobre o papel dos dados sint√©ticos nas regulamenta√ß√µes de privacidade e prote√ß√£o de dados nos Estados Unidos e Uni√£o Europeia.\
    üîó [Leia mais](https://jipel.law.nyu.edu/what-is-the-place-of-synthetic-data-in-us-and-eu-laws/)

### üóìÔ∏è 15/03/2024 - Iowa Law Review: Implica√ß√µes Legais da Revolu√ß√£o dos Dados Sint√©ticos

-   **Explora√ß√£o do impacto jur√≠dico** da gera√ß√£o de dados sint√©ticos no cen√°rio regulat√≥rio internacional.\
    üîó [Leia mais](https://ilr.law.uiowa.edu/volume-109-issue-3/2024/03/synthetic-data-legal-implications-data-generation-revolution)

------------------------------------------------------------------------

### üóìÔ∏è 22/06/2022 - Gartner: Dados Sint√©ticos s√£o o Futuro da IA?

-   **Gartner** explora como os dados sint√©ticos podem se tornar a **principal fonte de treinamento** para IA nos pr√≥ximos anos.\
    üîó [Leia mais](https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai)

### üóìÔ∏è 14/10/2022 - MIT Technology Review: Dados Sint√©ticos e a Nova Fronteira da IA

-   **Ado√ß√£o crescente** de dados sint√©ticos e seu papel fundamental no avan√ßo da **intelig√™ncia artificial**.\
    üîó [Leia mais](https://mittechreview.com.br/dados-sinteticos-a-nova-fronteira-da-inteligencia-artificial/)

### üóìÔ∏è 18/06/2022 - Forbes: Dados Sint√©ticos Transformando a Intelig√™ncia Artificial

-   Como os **dados sint√©ticos** podem revolucionar o treinamento de modelos de **machine learning**.\
    üîó [Leia mais](https://forbes.com.br/forbes-tech/2022/06/dados-sinteticos-estao-prestes-a-transformar-a-inteligencia-artificial/)

### üóìÔ∏è 12/08/2022 - J√° ouviu falar em Dados Sint√©ticos?

-   Segundo o **Gartner**, at√© 2024, **60% dos dados** utilizados no desenvolvimento de IA e analytics ser√£o **gerados sinteticamente**.\
    üîó [Leia mais](https://www.eucapacito.com.br/tecnologia/ja-ouviu-falar-em-dados-sinteticos/)

### Acesse o notebook criado pelo prof. Leandro Coelho sobre dados sint√©ticos

-   [Aqui em nosso Drive √© poss√≠vel acessar o notebook do prof. Leandro sobre gera√ß√£o de dados sint√©ticos, sem necessariamente ficarmos limitados a s√©ries temporais financeiras](https://drive.google.com/file/d/1XpqoCJ_fbqDRex2XRSvik7uq0BePcrXw/view?usp=drive_link)

# Pr√≥ximos passos

Ap√≥s selecionar com seu grupo (de at√© no m√°ximo 4 integrantes) se v√£o utilizar:

-   dados de datasets conhecidos,
-   dataset obtido a partir de dados reais via APIs
-   conjunto de dados (portfolio ou carteira) artificializada com alguma t√©cnica de gera√ß√£o de dados sint√©ticos

[Preencha a planilha a seguir no nosso Google Sheets aqui](https://docs.google.com/spreadsheets/d/11zM480JTGnJuDgGZIXadHUrZQb4CmSyRVNQIwLkQGS0/edit?usp=sharing)

<iframe src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTFbeodBeMyHsSjHVNVEWvgl7qaz7v8ji5ixK66Oi_tfLuX0VuE05xHClrS_dxrEK5jKbwTNlhIUzx4/pubhtml?widget=true&amp;headers=false">

</iframe>

$\Rightarrow$ e acompanhe [nosso cronograma da disciplina e do projeto](https://profrhozon.github.io/site/EmentaBigDataFinProj.html) em para evoluirem e apresentarem em cada encontro cada entrega que for solicitada.

¬†

¬†

------------------------------------------------------------------------

# References

------------------------------------------------------------------------

Coelho, L., S. 

Stasinopoulos, D. M., Rigby, R. A., Heller, G. Z., & Lovell, D. (2017). **Generalized Additive Models for Location, Scale and Shape (GAMLSS) in R: The gamlss package.** The R Journal, 9(2), 288‚Äì300.

Lo, A. W. & MacKinlay, A. C. (2011). **A Non-Random Walk Down Wall Street.** Princeton University Press.

Cont, R. (2001). **Empirical properties of asset returns: stylized facts and statistical issues.** Quantitative Finance, 1(2), 223‚Äì236.\
[DOI: 10.1088/1469-7688/1/2/304](https://doi.org/10.1088/1469-7688/1/2/304)

Goodfellow, I., Bengio, Y., & Courville, A. (2016). **Deep Learning.** MIT Press.

Brockwell, P. J., & Davis, R. A. (2016). **Introduction to Time Series and Forecasting.** Springer.

McKinney, W. (2017). **Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython.** O'Reilly Media.

Kingma, D. P., & Welling, M. (2013). **Auto-Encoding Variational Bayes.** arXiv preprint arXiv:1312.6114.\
[Link para o paper](https://arxiv.org/abs/1312.6114)

Radford, A., Metz, L., & Chintala, S. (2015). **Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.** arXiv preprint arXiv:1511.06434.\
[Link para o paper](https://arxiv.org/abs/1511.06434)

**Cuenca, P., Passos, A., Sanseviero, O., Whitaker, J. (2023)**. [Hands-On generative AI with transformers and diffusion models](https://www.oreilly.com/library/view/hands-on-generative-ai/9781098149239/), O'Reilly Media.

**El Eman, K., Mosquera, L., Hoptroff, R. (2020)**. [Practical synthetic data generation: Balancing privacy and the broad availability of data](https://www.oreilly.com/library/view/practical-synthetic-data/9781492072737/), O'Reilly Media.

**G√ºrsakal, N., √áelik, S., Biri≈ü√ßi, E. (2022)**. [Synthetic data for deep learning: Generate synthetic data for decision making and applications with Python and R](https://link.springer.com/book/10.1007/978-1-4842-8587-9), Apress. [Code](https://github.com/Apress/synthetic-data-deep-learning)

**Mao, X., Li, Q. (2021)**. [Generative adversarial networks for image generation](https://link.springer.com/book/10.1007/978-981-33-6048-8), Springer, Berlin, Germany.

¬†

¬†
